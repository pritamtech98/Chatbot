{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing the dataset \n",
    "with open('dataset/cornell movie-dialogs corpus/movie_lines.txt', 'r+', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "with open('dataset/cornell movie-dialogs corpus/movie_conversations.txt', 'r+', encoding='utf-8', errors='ignore') as f:\n",
    "    conversations = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making Dictionary of mapping between lines to Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2line = {}\n",
    "for line in lines:\n",
    "    _line = line.split(\" +++$+++ \")\n",
    "    if(len(_line)) == 5:\n",
    "        id2line[_line[0]] = _line[-1][:-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a list of all the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_id = []\n",
    "\n",
    "for conversation in conversations[:-1]:\n",
    "    _conversation = conversation.split(' +++$+++ ')[-1][1:-2].replace(\"'\", \"\").replace(\" \", \"\")\n",
    "    conversations_id.append(_conversation.split(\",\"))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making the list of questions and its answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conversation in conversations_id:\n",
    "    for i in range(len(conversation) - 1):\n",
    "        questions.append(id2line[conversation[i]])\n",
    "        answers.append(id2line[conversation[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(phrase):\n",
    "    phrase = phrase.lower()\n",
    "    \n",
    "    ## general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    \n",
    "    ## specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"[-()+=*/$%@!~<>?.,;:#{}]\", \"\", phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getting cleaned questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_questions = [clean_text(text) for text in questions]\n",
    "clean_answers = [clean_text(text) for text in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.', \"Well, I thought we'd start with pronunciation, if that's okay with you.\", 'Not the hacking and gagging and spitting part.  Please.', \"You're asking me out.  That's so cute. What's your name again?\", \"No, no, it's my fault -- we didn't have a proper introduction ---\"]\n",
      "\n",
      "['can we make this quick  roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad  again', \"well i thought we would start with pronunciation if that's okay with you\", 'not the hacking and gagging and spitting part  please', \"you are asking me out  that's so cute what's your name again\", \"no no it's my fault  we did not have a proper introduction \"]\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5], end=\"\\n\\n\")\n",
    "print(clean_questions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a dictonary that will map our words with its no of occurences` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in clean_questions:\n",
    "    for word in sent.split():\n",
    "        if word2count.get(word) is None:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "for sent in clean_answers:\n",
    "    for word in sent.split():\n",
    "        if word2count.get(word) is None:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating two dictionaries of questions and answers which maps them to a unique integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20   ## hyperparameter\n",
    "questionsword2int = {}\n",
    "answersword2int = {}\n",
    "word_index = 0\n",
    "\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        questionsword2int[word] = word_index\n",
    "        word_index += 1\n",
    "        \n",
    "word_index = 0 \n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        answersword2int[word] = word_index\n",
    "        word_index += 1\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding the last tokens inside our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "for token in tokens:\n",
    "    questionsword2int[token] = len(questionsword2int) + 1\n",
    "    \n",
    "for token in tokens:\n",
    "    answersword2int[token] = len(answersword2int) + 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the inverse dictionary for answersword2int dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersints2word = dict((value, key) for (key, value) in answersword2int.items())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding the EOS token in clean_answers list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_answers)):\n",
    "    clean_answers[i] += ' <EOS>'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Translating all the questions and answers into the integers\n",
    "##### And converting the filtered words by OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_into_int = []\n",
    "answers_into_int = []\n",
    "\n",
    "for question in clean_questions:\n",
    "    ints = []\n",
    "    for word in question.split():\n",
    "        if word not in questionsword2int.keys():\n",
    "            ints.append(questionsword2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(questionsword2int[word])\n",
    "    questions_into_int.append(ints)\n",
    "    \n",
    "for answer in clean_answers:\n",
    "    ints = []\n",
    "    for word in answer.split():\n",
    "        if word not in answersword2int.keys():\n",
    "            ints.append(answersword2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(answersword2int[word])\n",
    "    answers_into_int.append(ints)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sorting the questions and answers by length of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_clean_questions = []\n",
    "sorted_clean_answers = []\n",
    "\n",
    "maxlength = 25\n",
    "\n",
    "for length in range(1, maxlength+1):\n",
    "    for i, question in enumerate(questions_into_int):\n",
    "        if(len(question) == length):\n",
    "            sorted_clean_questions.append(questions_into_int[i])\n",
    "            sorted_clean_answers.append(answers_into_int[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
